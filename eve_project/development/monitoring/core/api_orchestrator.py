import sys
import os
import subprocess
import threading
import uuid
import logging
from typing import Dict, Any
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

# --- Configuration Ollama ---
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.1:8b")

# --- Configuration des Chemins ---
CREW_A_PATH = os.getenv("CREW_A_PATH", "crew_a")
CREW_B_PATH = os.getenv("CREW_B_PATH", "crew_b")
MODULE_A_NAME = "eve_genesis___crew_a_construction_eveil"
MODULE_B_NAME = "eve_genesis___crew_b"

# --- Configuration des Logs ---
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# --- Base de Donn√©es en M√©moire ---
tasks_status: Dict[str, Dict[str, Any]] = {}

# --- Initialisation de l'API FastAPI ---
app = FastAPI(
    title="EVE GENESIS Orchestrator API - Ollama Edition",
    description="API d'orchestration pour le syst√®me EVE GENESIS utilisant Ollama",
    version="1.0.0",
)

# Middleware CORS pour permettre les requ√™tes cross-origin
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


def setup_ollama_environment():
    """Configure l'environnement pour utiliser Ollama."""
    env_vars = {
        "OLLAMA_BASE_URL": OLLAMA_BASE_URL,
        "OLLAMA_MODEL": OLLAMA_MODEL,
        "USE_OLLAMA": "true",
        "DISABLE_OPENAI": "true",
    }

    for key, value in env_vars.items():
        os.environ[key] = value
        logger.info(f"Variable d'environnement d√©finie: {key}={value}")


def check_ollama_availability():
    """V√©rifie si Ollama est accessible."""
    try:
        import requests

        response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
        if response.status_code == 200:
            logger.info("Ollama est accessible et fonctionne")
            return True
        else:
            logger.warning(f"Ollama r√©pond avec le code: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"Impossible de contacter Ollama: {e}")
        return False


def run_crew(crew_path: str, module_name: str, crew_name: str, task_id: str) -> bool:
    """
    Ex√©cute un crew avec l'environnement Ollama configur√©.
    """
    original_directory = os.getcwd()

    try:
        # Configuration de l'environnement Ollama
        setup_ollama_environment()

        # Changement vers le r√©pertoire du crew
        os.chdir(crew_path)

        # V√©rification que le module existe
        module_path = f"src/{module_name}/main.py"
        if not os.path.exists(module_path):
            raise FileNotFoundError(f"Module non trouv√©: {module_path}")

        command = [sys.executable, module_path, "run"]
        logger.info(f"Ex√©cution de {crew_name}: {' '.join(command)}")

        # Mise √† jour du statut
        tasks_status[task_id]["details"] = f"Ex√©cution de {crew_name} en cours..."

        # Ex√©cution avec timeout
        result = subprocess.run(
            command,
            capture_output=True,
            text=True,
            encoding="utf-8",
            check=False,
            timeout=3600,  # Timeout de 1 heure
        )

        # Gestion des r√©sultats
        if result.returncode != 0:
            error_details = f"√âchec de {crew_name} (code: {result.returncode})\n"
            error_details += "=== STDOUT ===\n"
            error_details += result.stdout or "Aucune sortie standard\n"
            error_details += "\n=== STDERR ===\n"
            error_details += result.stderr or "Aucune erreur standard\n"

            logger.error(error_details)
            tasks_status[task_id].update(
                {"status": "failed", "details": error_details, "crew": crew_name}
            )
            return False

        # Succ√®s
        success_message = f"{crew_name} termin√© avec succ√®s"
        logger.info(success_message)

        # Sauvegarde des logs de sortie (tronqu√©s)
        stdout_preview = (
            result.stdout[:1000] + "..." if len(result.stdout) > 1000 else result.stdout
        )
        tasks_status[task_id][
            "details"
        ] = f"{success_message}\nSortie: {stdout_preview}"

        return True

    except subprocess.TimeoutExpired:
        error_msg = f"Timeout atteint pour {crew_name} (>1h)"
        logger.error(error_msg)
        tasks_status[task_id].update(
            {"status": "failed", "details": error_msg, "crew": crew_name}
        )
        return False

    except Exception as e:
        error_msg = f"Erreur critique lors de l'ex√©cution de {crew_name}: {str(e)}"
        logger.error(error_msg)
        tasks_status[task_id].update(
            {"status": "failed", "details": error_msg, "crew": crew_name}
        )
        return False

    finally:
        os.chdir(original_directory)


def run_full_sequence(task_id: str):
    """
    Ex√©cute la s√©quence compl√®te Crew A -> Crew B avec Ollama.
    """
    logger.info(f"[{task_id}] D√©marrage de la s√©quence EVE GENESIS")

    # V√©rification initiale d'Ollama
    if not check_ollama_availability():
        tasks_status[task_id].update(
            {
                "status": "failed",
                "details": "Ollama n'est pas accessible. V√©rifiez qu'Ollama est d√©marr√©.",
            }
        )
        return

    tasks_status[task_id].update(
        {
            "status": "running",
            "details": "Initialisation - V√©rification d'Ollama r√©ussie",
            "progress": 0,
        }
    )

    # √âtape 1: Crew A (Construction & √âveil)
    logger.info(f"[{task_id}] Phase 1: Ex√©cution du Crew A (Construction & √âveil)")
    tasks_status[task_id].update(
        {
            "details": "Phase 1: Crew A (Construction & √âveil) en cours...",
            "progress": 10,
        }
    )

    if not run_crew(CREW_A_PATH, MODULE_A_NAME, "Crew A", task_id):
        logger.error(f"[{task_id}] √âchec du Crew A - Arr√™t de la s√©quence")
        return

    # √âtape 2: Crew B (Enrichissement & √âvolution)
    logger.info(
        f"[{task_id}] Phase 2: Ex√©cution du Crew B (Enrichissement & √âvolution)"
    )
    tasks_status[task_id].update(
        {
            "details": "Phase 2: Crew B (Enrichissement & √âvolution) en cours...",
            "progress": 60,
        }
    )

    if not run_crew(CREW_B_PATH, MODULE_B_NAME, "Crew B", task_id):
        logger.error(f"[{task_id}] √âchec du Crew B - Arr√™t de la s√©quence")
        return

    # Finalisation
    tasks_status[task_id].update(
        {
            "status": "completed",
            "details": "S√©quence EVE GENESIS termin√©e avec succ√®s ! EVE est maintenant op√©rationnelle.",
            "progress": 100,
        }
    )
    logger.info(f"[{task_id}] S√©quence EVE GENESIS termin√©e avec succ√®s")


@app.get("/")
def root():
    """Point d'entr√©e racine de l'API."""
    return {
        "message": "EVE GENESIS Orchestrator API - Ollama Edition",
        "version": "1.0.0",
        "ollama_url": OLLAMA_BASE_URL,
        "ollama_model": OLLAMA_MODEL,
        "status": "operational",
    }


@app.get("/health")
def health_check():
    """V√©rification de sant√© de l'API et d'Ollama."""
    ollama_status = check_ollama_availability()
    return {
        "api_status": "healthy",
        "ollama_status": "available" if ollama_status else "unavailable",
        "ollama_url": OLLAMA_BASE_URL,
        "model": OLLAMA_MODEL,
    }


@app.post("/start_eve_genesis")
def start_sequence():
    """
    D√©marre la s√©quence compl√®te EVE GENESIS avec Ollama.
    """
    # V√©rification pr√©alable d'Ollama
    if not check_ollama_availability():
        raise HTTPException(
            status_code=503,
            detail="Ollama n'est pas accessible. V√©rifiez qu'Ollama est d√©marr√© et accessible.",
        )

    task_id = str(uuid.uuid4())
    tasks_status[task_id] = {
        "status": "pending",
        "details": "S√©quence en attente de d√©marrage...",
        "progress": 0,
        "created_at": str(uuid.uuid1().time),
    }

    # Lancement asynchrone
    thread = threading.Thread(target=run_full_sequence, args=(task_id,))
    thread.daemon = True  # Thread daemon pour √©viter les blocages
    thread.start()

    logger.info(f"Nouvelle s√©quence EVE GENESIS d√©marr√©e: {task_id}")

    return {
        "message": "S√©quence EVE GENESIS d√©marr√©e avec Ollama",
        "task_id": task_id,
        "ollama_model": OLLAMA_MODEL,
        "status_url": f"/status/{task_id}",
    }


@app.get("/status/{task_id}")
def get_status(task_id: str):
    """
    R√©cup√®re le statut d'une t√¢che en cours.
    """
    if task_id not in tasks_status:
        raise HTTPException(status_code=404, detail=f"T√¢che {task_id} non trouv√©e")

    return tasks_status[task_id]


@app.get("/tasks")
def list_tasks():
    """
    Liste toutes les t√¢ches en cours et termin√©es.
    """
    return {"total_tasks": len(tasks_status), "tasks": tasks_status}


@app.delete("/tasks/{task_id}")
def delete_task(task_id: str):
    """
    Supprime une t√¢che de l'historique.
    """
    if task_id not in tasks_status:
        raise HTTPException(status_code=404, detail=f"T√¢che {task_id} non trouv√©e")

    del tasks_status[task_id]
    return {"message": f"T√¢che {task_id} supprim√©e"}


if __name__ == "__main__":
    print("=" * 60)
    print("EVE GENESIS Orchestrator API - Ollama Edition")
    print("=" * 60)
    print(f"Ollama URL: {OLLAMA_BASE_URL}")
    print(f"Mod√®le: {OLLAMA_MODEL}")
    print("=" * 60)

    # V√©rification initiale d'Ollama
    if check_ollama_availability():
        print("‚úÖ Ollama est accessible")
    else:
        print("‚ùå Ollama n'est pas accessible")
        print("   Assurez-vous qu'Ollama est d√©marr√© avec: ollama serve")

    print("üöÄ D√©marrage du serveur API...")
    print("üìñ Documentation: http://127.0.0.1:8000/docs")
    print("üîç Sant√©: http://127.0.0.1:8000/health")
    print("=" * 60)

    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")
