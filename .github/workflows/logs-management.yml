name: ðŸ“Š Logs Management System

on:
  push:
    paths: ['eve/interfaces/logs/**', '**/*.py']
  schedule:
    - cron: '0 */3 * * *'  # Toutes les 3 heures
  workflow_dispatch:

jobs:
  logs-management:
    name: Advanced Logs System Validation
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v5
    
    - name: Setup Logging Environment
      uses: actions/setup-python@v6
      with:
        python-version: '3.11'
        
    - name: Install Logging Dependencies
      run: |
        pip install logging-advanced structured-logging
        pip install elasticsearch-logger prometheus-logging
        pip install log-analysis log-aggregation
        
    - name: Test EVE Logs Manager
      run: |
        echo "ðŸ“Š VALIDATION SYSTÃˆME LOGS EVE" > logs-report.md
        echo "==============================" >> logs-report.md
        echo "" >> logs-report.md
        
        # Analyser systÃ¨me logs EVE
        if [ -d "eve/interfaces/logs" ]; then
          echo "## ðŸ“‹ SystÃ¨me Logs EVE" >> logs-report.md
          
          log_modules=$(find eve/interfaces/logs/ -name "*.py" | wc -l)
          echo "- **Modules logs**: $log_modules dÃ©tectÃ©s" >> logs-report.md
          echo "" >> logs-report.md
          
          # Chercher gestionnaires logs spÃ©cialisÃ©s
          log_handlers=("file_handler" "console_handler" "database_handler" "network_handler")
          for handler in "${log_handlers[@]}"; do
            if find eve/interfaces/logs/ -name "*$handler*" -o -name "*${handler}*" | grep -q .; then
              echo "- âœ… **$handler**: DÃ©tectÃ©" >> logs-report.md
            else
              echo "- âš ï¸ **$handler**: Non trouvÃ©" >> logs-report.md
            fi
          done
          echo "" >> logs-report.md
        fi
        
    - name: Advanced Logging System Test
      run: |
        echo "## ðŸ”§ Test SystÃ¨me Logging AvancÃ©" >> logs-report.md
        echo "" >> logs-report.md
        
        # Test systÃ¨me logging complet
        python -c "
        import logging
        import json
        import time
        from datetime import datetime
        
        print('ðŸ”§ Test systÃ¨me logging avancÃ©...')
        
        # Configuration logging structurÃ©
        class StructuredFormatter(logging.Formatter):
            def format(self, record):
                log_entry = {
                    'timestamp': datetime.fromtimestamp(record.created).isoformat(),
                    'level': record.levelname,
                    'module': record.module,
                    'function': record.funcName,
                    'line': record.lineno,
                    'message': record.getMessage(),
                    'thread': record.thread,
                    'process': record.process
                }
                return json.dumps(log_entry, ensure_ascii=False)
        
        # Configurer loggers multiples
        loggers = {
            'agi.core': logging.getLogger('agi.core'),
            'eve.cognitive': logging.getLogger('eve.cognitive'),
            'eve.simulation': logging.getLogger('eve.simulation'),
            'eve.development': logging.getLogger('eve.development')
        }
        
        # Handlers multiples
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(StructuredFormatter())
        
        file_handler = logging.FileHandler('agi_eve_system.log')
        file_handler.setFormatter(StructuredFormatter())
        
        # Configuration loggers
        for name, logger in loggers.items():
            logger.setLevel(logging.DEBUG)
            logger.addHandler(console_handler)
            logger.addHandler(file_handler)
        
        # Test logs structurÃ©s
        loggers['agi.core'].info('SystÃ¨me AGI initialisÃ©', extra={'version': '1.0', 'mode': 'production'})
        loggers['eve.cognitive'].debug('Module cognitif activÃ©', extra={'brain_status': 'active'})
        loggers['eve.simulation'].warning('Simulation charge Ã©levÃ©e', extra={'cpu_usage': 85})
        loggers['eve.development'].error('Erreur validation code', extra={'file': 'test.py', 'line': 42})
        
        print('âœ… Logging structurÃ©: 4 loggers configurÃ©s')
        print('âœ… Handlers: Console + File')
        print('âœ… Format: JSON structurÃ©')
        
        # Test performance logging
        start_time = time.time()
        for i in range(1000):
            loggers['agi.core'].info(f'Message performance {i}')
        end_time = time.time()
        
        performance = 1000 / (end_time - start_time)
        print(f'âœ… Performance: {performance:.0f} logs/sec')
        
        if performance > 500:
            print('âœ… Performance logging: Excellente')
        else:
            print('âš ï¸ Performance logging: Ã€ optimiser')
        " >> logs-report.md
        
    - name: Log Analysis and Monitoring
      run: |
        echo "" >> logs-report.md
        echo "## ðŸ“ˆ Analyse et Monitoring Logs" >> logs-report.md
        echo "" >> logs-report.md
        
        # Analyser logs systÃ¨me
        python -c "
        import re
        import json
        from collections import Counter, defaultdict
        from datetime import datetime
        
        print('ðŸ“ˆ Analyse logs systÃ¨me...')
        
        # Lire et analyser logs existants
        log_stats = {
            'total_entries': 0,
            'levels': Counter(),
            'modules': Counter(),
            'errors': [],
            'warnings': [],
            'timeline': defaultdict(int)
        }
        
        try:
            with open('agi_eve_system.log', 'r') as f:
                for line in f:
                    try:
                        log_entry = json.loads(line.strip())
                        log_stats['total_entries'] += 1
                        log_stats['levels'][log_entry['level']] += 1
                        log_stats['modules'][log_entry['module']] += 1
                        
                        # Extraire heure pour timeline
                        timestamp = log_entry['timestamp']
                        hour = timestamp.split('T')[1][:2]
                        log_stats['timeline'][hour] += 1
                        
                        # Collecter erreurs et warnings
                        if log_entry['level'] == 'ERROR':
                            log_stats['errors'].append(log_entry['message'])
                        elif log_entry['level'] == 'WARNING':
                            log_stats['warnings'].append(log_entry['message'])
                            
                    except json.JSONDecodeError:
                        pass  # Ignorer lignes non-JSON
                        
        except FileNotFoundError:
            print('âš ï¸ Fichier log non trouvÃ© - GÃ©nÃ©rer logs d\\'abord')
        
        # Afficher statistiques
        print(f'- **Total entrÃ©es**: {log_stats[\"total_entries\"]}')
        
        if log_stats['levels']:
            for level, count in log_stats['levels'].most_common():
                print(f'- **{level}**: {count} entrÃ©es')
        
        if log_stats['modules']:
            print('- **Modules les plus actifs**:')
            for module, count in log_stats['modules'].most_common(3):
                print(f'  - {module}: {count}')
        
        # Alertes
        error_count = log_stats['levels']['ERROR']
        warning_count = log_stats['levels']['WARNING']
        
        if error_count > 10:
            print(f'ðŸš¨ **ALERTE**: {error_count} erreurs dÃ©tectÃ©es')
        elif warning_count > 50:
            print(f'âš ï¸ **ATTENTION**: {warning_count} warnings')
        else:
            print('âœ… **Logs**: Niveau normal')
        
        # Recommandations
        total = log_stats['total_entries']
        if total > 10000:
            print('ðŸ’¡ **Recommandation**: Rotation logs nÃ©cessaire')
        if error_count / max(total, 1) > 0.1:
            print('ðŸ’¡ **Recommandation**: Taux d\\'erreur Ã©levÃ© - Investigation requise')
        " >> logs-report.md
        
    - name: Log Aggregation and Alerting
      run: |
        echo "" >> logs-report.md
        echo "## ðŸš¨ AgrÃ©gation et Alertes Logs" >> logs-report.md
        echo "" >> logs-report.md
        
        # SystÃ¨me d'alertes basÃ© sur logs
        python -c "
        import json
        import re
        from datetime import datetime, timedelta
        
        print('ðŸš¨ Test systÃ¨me alertes logs...')
        
        class LogAlertSystem:
            def __init__(self):
                self.rules = [
                    {'pattern': r'ERROR', 'threshold': 5, 'window': 300, 'severity': 'high'},
                    {'pattern': r'WARNING.*memory', 'threshold': 10, 'window': 600, 'severity': 'medium'},
                    {'pattern': r'CRITICAL', 'threshold': 1, 'window': 60, 'severity': 'critical'},
                    {'pattern': r'exception|traceback', 'threshold': 3, 'window': 300, 'severity': 'high'}
                ]
                self.alerts = []
            
            def check_alerts(self, log_entries):
                for rule in self.rules:
                    pattern = rule['pattern']
                    threshold = rule['threshold']
                    severity = rule['severity']
                    
                    # Compter occurrences
                    matches = [entry for entry in log_entries if re.search(pattern, entry, re.IGNORECASE)]
                    
                    if len(matches) >= threshold:
                        alert = {
                            'rule': pattern,
                            'count': len(matches),
                            'threshold': threshold,
                            'severity': severity,
                            'timestamp': datetime.now().isoformat()
                        }
                        self.alerts.append(alert)
                
                return self.alerts
        
        # Test systÃ¨me alertes
        alert_system = LogAlertSystem()
        
        # Logs test pour dÃ©clencher alertes
        test_logs = [
            'ERROR: Database connection failed',
            'ERROR: Authentication error',
            'ERROR: File not found',
            'ERROR: Network timeout',
            'ERROR: Permission denied',
            'ERROR: Critical system failure',
            'WARNING: High memory usage detected',
            'WARNING: Memory leak suspected',
            'CRITICAL: System shutdown imminent',
            'Exception in thread main: NullPointerException'
        ]
        
        alerts = alert_system.check_alerts(test_logs)
        
        print(f'âœ… SystÃ¨me alertes: {len(alerts)} alertes gÃ©nÃ©rÃ©es')
        
        for alert in alerts:
            severity_icon = {'low': 'ðŸŸ¡', 'medium': 'ðŸŸ ', 'high': 'ðŸ”´', 'critical': 'ðŸš¨'}
            icon = severity_icon.get(alert['severity'], 'âšª')
            print(f'{icon} **{alert[\"severity\"].upper()}**: {alert[\"rule\"]} - {alert[\"count\"]} occurrences')
        
        # Test notification systÃ¨me
        if any(alert['severity'] == 'critical' for alert in alerts):
            print('ðŸš¨ **ALERTE CRITIQUE**: Notification immÃ©diate requise')
        elif any(alert['severity'] == 'high' for alert in alerts):
            print('ðŸ”´ **ALERTE HAUTE**: Intervention rapide recommandÃ©e')
        else:
            print('âœ… **SystÃ¨me stable**: Aucune alerte critique')
        " >> logs-report.md
        
    - name: Upload Logs Management Report
      uses: actions/upload-artifact@v3
      with:
        name: logs-management-report
        path: |
          logs-report.md
          agi_eve_system.log
